swagger: '2.0'
info:
  title: OpenAI
  description: >-
    Connect to the OpenAI API and use the Power of GPT3, API key must be entered
    as "Bearer YOUR_API_KEY"
  version: '1.0'
  contact:
    name: David Soden & Robin RosengrÃ¼n
    url: https://DavidSoden.com
host: api.openai.com
basePath: /
schemes:
  - https
consumes: []
produces: []
paths:
  /v1/engines/{engine}/completions:
    post:
      responses:
        '200':
          description: GPT3 completed your prompt
          schema:
            type: object
            properties:
              id:
                type: string
                description: id
              object:
                type: string
                description: object
              created:
                type: integer
                format: int32
                description: created
              model:
                type: string
                description: Which GPT3 Engine was used
                title: Model
                x-ms-visibility: internal
              choices:
                type: array
                items:
                  type: object
                  properties:
                    text:
                      type: string
                      description: Completion text
                      title: Text
                    index:
                      type: integer
                      format: int32
                      description: Number of completion
                      title: Index
                    logprobs:
                      type: string
                      description: >-
                        Include the log probabilities on the logprobs most
                        likely tokens, as well the chosen tokens. For example,
                        if logprobs is 3, the API will return a list of the 3
                        most likely tokens.
                      title: Logprobs
                    finish_reason:
                      title: Finish reason
                      type: string
                      description: >-
                        Reason why the text finished (stop condition / natural
                        end / length)
                description: Returned Completion(s)
      summary: GPT3 Completes your prompt
      description: GPT3 Completes your prompt
      operationId: Completion
      parameters:
        - name: engine
          in: path
          type: string
          description: >-
            The used engine, choose between text-davinci-002/003,
            text-curie-001, text-babbage-001, text-ada-001
          required: true
          default: text-davinci-003
          x-ms-visibility: important
          x-ms-summary: Engine
          enum:
            - text-davinci-003
            - text-davinci-002
            - text-curie-001
            - text-babbage-001
            - text-ada-001
          x-ms-enum-values:
            - displayName: DaVinci (new)
              value: text-davinci-003
            - displayName: DaVinci (old)
              value: text-davinci-002
            - displayName: Curie
              value: text-curie-001
            - displayName: Babbage
              value: text-babbage-001
            - displayName: Ada
              value: text-ada-001
        - name: body
          in: body
          required: true
          schema:
            type: object
            properties:
              prompt:
                type: string
                description: Text that will be completed by GPT3
                title: prompt
                default: >-
                  What is your favorite animal and why? Tell me also about the
                  size and weight of this animal.
              'n':
                type: integer
                format: int32
                description: How many completions to generate for each prompt
                default: 1
              best_of:
                type: integer
                format: int32
                description: >-
                  If set to more than 1, generates multiple completions
                  server-side and returns the "best". Must be greater than "n".
                  Use with caution, can consume a lot of tokens.
                default: 1
              temperature:
                type: number
                format: float
                description: >-
                  Higher values means the model will take more risks. Try 0.9
                  for more creative applications, and 0 (argmax sampling) for
                  ones with a well-defined answer. Use this OR top p
                title: temperature
                default: 1
              max_tokens:
                type: integer
                format: int32
                description: >-
                  One token equals roughly 4 characters of text (up to 4000
                  tokens between prompt and completion)
                title: max tokens
                default: 100
              top_p:
                type: number
                format: float
                description: >-
                  An alternative to sampling with temperature, called nucleus
                  sampling, where the model considers the results of the tokens
                  with top_p probability mass. So 0.1 means only the tokens
                  comprising the top 10% probability mass are considered.
                title: top p
              frequency_penalty:
                type: number
                format: float
                description: >-
                  Number between -2.0 and 2.0. Positive values penalize new
                  tokens based on their existing frequency in the text so far,
                  decreasing the models likelihood to repeat the same line
                  verbatim.
                title: frequency penalty
                default: 0
              presence_penalty:
                type: number
                format: float
                description: >-
                  Number between -2.0 and 2.0. Positive values penalize new
                  tokens based on whether they appear in the text so far,
                  increasing the models likelihood to talk about new topics.
                title: presence penalty
                default: 0
              user:
                type: string
                title: user
                description: >-
                  A unique identifier representing your end-user, which will
                  help OpenAI to monitor and detect abuse
              stop:
                type: array
                items:
                  type: string
                description: >-
                  Up to 4 sequences where the API will stop generating further
                  tokens. The returned text will not contain the stop sequence
            required:
              - prompt
      x-ms-visibility: important
  /v1/images/generations:
    post:
      responses:
        '200':
          description: default
          schema:
            type: object
            properties:
              created:
                type: integer
                format: int32
                description: Unique Creation ID from OpenAI
                title: created
                x-ms-visibility: internal
              data:
                type: array
                items:
                  type: object
                  properties:
                    url:
                      type: string
                      description: URL to created Image
                      title: url
                    b64_json:
                      type: string
                      description: Image in base64 format
                      title: b64image
                      format: byte
                description: data
      summary: Create an Image
      operationId: CreateImage
      parameters:
        - name: body
          in: body
          required: false
          schema:
            type: object
            properties:
              prompt:
                type: string
                description: The prompt that describes the image
                title: prompt
                default: An elephant with a fedora in a dark room, digital art
              'n':
                type: integer
                format: int32
                description: Number of images from 1 to 10
                title: Number of images
                default: 1
              size:
                type: string
                title: size
                description: >-
                  The size of the generated images. 256x256, 512x512 or
                  1024x1024 (default: 1024x1024)
                enum:
                  - 256x256
                  - 512x512
                  - 1024x1024
                default: 1024x1024
              response_format:
                type: string
                title: format
                description: >-
                  Get url to picture or receive it in base64 format (default:
                  url)
                enum:
                  - url
                  - b64_json
                default: url
            required:
              - prompt
      description: DallE2 creates an image from your prompt
  /v1/moderations:
    post:
      responses:
        default:
          description: default
          schema:
            type: object
            properties:
              id:
                type: string
                description: id
              model:
                type: string
                description: model
              results:
                type: array
                items:
                  type: object
                  properties:
                    flagged:
                      type: boolean
                      description: flagged
                    categories:
                      type: object
                      properties:
                        sexual:
                          type: boolean
                          description: sexual
                        hate:
                          type: boolean
                          description: hate
                        violence:
                          type: boolean
                          description: violence
                        self-harm:
                          type: boolean
                          description: self-harm
                        sexual/minors:
                          type: boolean
                          description: sexual/minors
                        hate/threatening:
                          type: boolean
                          description: hate/threatening
                        violence/graphic:
                          type: boolean
                          description: violence/graphic
                      description: categories
                    category_scores:
                      type: object
                      properties:
                        sexual:
                          type: number
                          format: float
                          description: sexual
                        hate:
                          type: number
                          format: float
                          description: hate
                        violence:
                          type: number
                          format: float
                          description: violence
                        self-harm:
                          type: number
                          format: float
                          description: self-harm
                        sexual/minors:
                          type: number
                          format: float
                          description: sexual/minors
                        hate/threatening:
                          type: number
                          format: float
                          description: hate/threatening
                        violence/graphic:
                          type: number
                          format: float
                          description: violence/graphic
                      description: category_scores
                description: results
      summary: Moderation
      description: >-
        Given a input text, outputs if the model classifies it as violating
        OpenAI's content policy.
      operationId: Moderation
      parameters:
        - name: Content-Type
          in: header
          required: true
          type: string
          default: application/json
          x-ms-visibility: internal
        - name: body
          in: body
          required: true
          schema:
            type: object
            properties:
              input:
                type: string
                description: input
                title: ''
                x-ms-visibility: important
                default: I will kill them
            required:
              - input
            x-ms-visibility: important
          x-ms-visibility: important
  /v1/edits:
    post:
      responses:
        default:
          description: default
          schema:
            type: object
            properties:
              object:
                type: string
                description: object
              created:
                type: integer
                format: int32
                description: created
              choices:
                type: array
                items:
                  type: object
                  properties:
                    text:
                      type: string
                      description: text
                    index:
                      type: integer
                      format: int32
                      description: index
                description: choices
              usage:
                type: object
                properties:
                  prompt_tokens:
                    type: integer
                    format: int32
                    description: prompt_tokens
                  completion_tokens:
                    type: integer
                    format: int32
                    description: completion_tokens
                  total_tokens:
                    type: integer
                    format: int32
                    description: total_tokens
                description: usage
      summary: Edits
      description: >-
        Given a prompt and an instruction, the model will return an edited
        version of the prompt.
      operationId: Edits
      parameters:
        - name: Content-Type
          in: header
          required: true
          type: string
          default: application/json
          x-ms-visibility: internal
        - name: body
          in: body
          required: true
          schema:
            type: object
            properties:
              model:
                type: string
                description: model
                title: Model
                default: text-davinci-edit-001
                x-ms-visibility: internal
              input:
                type: string
                description: The input text to use as a starting point for the edit.
                title: Input
                default: What day of the wek is it?
              instruction:
                type: string
                description: The instruction that tells the model how to edit the prompt.
                title: Intstruction
                default: Fix the spelling mistakes
            required:
              - input
              - instruction
              - model
definitions: {}
parameters: {}
responses: {}
securityDefinitions: {}
tags: []
x-ms-connector-metadata:
  - propertyName: Website
    propertyValue: https://openai.com/
  - propertyName: Privacy policy
    propertyValue: https://openai.com/api/policies/terms/
  - propertyName: Categories
    propertyValue: AI
